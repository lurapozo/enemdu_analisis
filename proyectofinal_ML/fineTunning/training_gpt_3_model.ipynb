{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Install OpenAI"
      ],
      "metadata": {
        "id": "ATMR7e017TEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca916-MW6yMj",
        "outputId": "038a4b09-fe7f-4fa3-8563-3a5a4d01e5df"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/76.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add OpenAI API KEY\n"
      ],
      "metadata": {
        "id": "YOJtKdY07XPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "API_KEY = \"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\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = API_KEY\n"
      ],
      "metadata": {
        "id": "m_o730Gc7RtD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing training file"
      ],
      "metadata": {
        "id": "pNfLw2EiKspX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "file_path = \"./prueba.json\"\n",
        "os.environ[\"FILE_PATH\"] = file_path\n",
        "\n",
        "!openai tools fine_tunes.prepare_data -f $file_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEGFK8WUJ6an",
        "outputId": "fa48e228-d481-410c-aba7-8b6dee06ca01"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Your JSON file appears to be in a JSONL format. Your file will be converted to JSONL format\n",
            "- Your file contains 36 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
            "- The input file should contain exactly two columns/keys per row. Additional columns/keys present are: ['promt']\n",
            "  WARNING: Some of the additional columns/keys contain `promt` in their name. These will be ignored, and the column/key `promt` will be used instead. This could also result from a duplicate column/key in the provided file.\n",
            "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
            "- Your data does not contain a common ending at the end of your completions. Having a common ending string appended to the end of the completion makes it clearer to the fine-tuned model where the completion should end. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples.\n",
            "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Necessary] Your format `JSON` will be converted to `JSONL`\n",
            "- [Necessary] Remove additional columns/keys: ['promt']\n",
            "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: y\n",
            "/usr/local/lib/python3.10/dist-packages/openai/validators.py:226: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  x[\"prompt\"] += suffix\n",
            "- [Recommended] Add a suffix ending `\\n` to all completions [Y/n]: y\n",
            "/usr/local/lib/python3.10/dist-packages/openai/validators.py:382: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  x[\"completion\"] += suffix\n",
            "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: y\n",
            "/usr/local/lib/python3.10/dist-packages/openai/validators.py:425: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  x[\"completion\"] = x[\"completion\"].apply(\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: y\n",
            "\n",
            "Wrote modified file to `./prueba_prepared.jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"./prueba_prepared.jsonl\"\n",
            "\n",
            "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n\"]` so that the generated texts ends at the expected place.\n",
            "Once your model starts training, it'll approximately take 2.94 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model creation\n",
        "**model_sufix** sufijo del modelo para facilitar su identificación.\n",
        "\n",
        "**selecion**: Modelo con el que se desea entrenar, davinci es el mejor\n"
      ],
      "metadata": {
        "id": "Yu6Sho3ontbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_sufix = \"clases_prueba\"\n",
        "selection = \"davinci\"\n",
        "!openai api fine_tunes.create -t ./prueba_prepared.jsonl -m $selection --suffix $model_sufix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79b0ee76-59ed-4058-f41a-9e8676fd401a",
        "id": "uYghKQpXqZIk"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rUpload progress:   0% 0.00/33.0k [00:00<?, ?it/s]\rUpload progress: 100% 33.0k/33.0k [00:00<00:00, 63.9Mit/s]\n",
            "Uploaded file from ./prueba_prepared.jsonl: file-NSW9LLVe4hdmWmJiwZQaSWBk\n",
            "Created fine-tune: ft-rJqQ47sSRthzG48pbhAknW08\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2023-09-04 00:21:24] Created fine-tune: ft-rJqQ47sSRthzG48pbhAknW08\n",
            "[2023-09-04 00:21:37] Fine-tune costs $1.50\n",
            "[2023-09-04 00:21:37] Fine-tune enqueued. Queue number: 0\n",
            "[2023-09-04 00:21:38] Fine-tune started\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model training\n",
        "\n",
        "**model_id** id del modelo, aparece después de *Created fine-tune:*"
      ],
      "metadata": {
        "id": "4-gWgybgskrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"ft-rJqQ47sSRthzG48pbhAknW08\"\n",
        "!openai api fine_tunes.follow -i $model_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic2yAXcFsnlb",
        "outputId": "73dee3c4-e876-4543-8f71-961563dfa26f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-09-04 00:21:24] Created fine-tune: ft-rJqQ47sSRthzG48pbhAknW08\n",
            "[2023-09-04 00:21:37] Fine-tune costs $1.50\n",
            "[2023-09-04 00:21:37] Fine-tune enqueued. Queue number: 0\n",
            "[2023-09-04 00:21:38] Fine-tune started\n",
            "[2023-09-04 00:23:29] Completed epoch 1/4\n",
            "[2023-09-04 00:23:45] Completed epoch 2/4\n",
            "[2023-09-04 00:24:02] Completed epoch 3/4\n",
            "[2023-09-04 00:24:19] Completed epoch 4/4\n",
            "[2023-09-04 00:25:03] Uploaded model: davinci:ft-espol:clases-prueba-2023-09-04-00-25-03\n",
            "[2023-09-04 00:25:04] Uploaded result file: file-63W1LGo6DUATwfQeKHQ1LaJ6\n",
            "[2023-09-04 00:25:04] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded 🎉\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-espol:clases-prueba-2023-09-04-00-25-03 -p <YOUR_PROMPT>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt"
      ],
      "metadata": {
        "id": "5CJY4XCNSYzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api completions.create -m davinci:ft-espol:clases-prueba-2023-09-04-00-25-03 -t 0.9 -M 100 -p \"Que es numpy de python?\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FhloELZTKux",
        "outputId": "cacdfe3f-6ade-4806-d870-d2a697618ce9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Que es numpy de python? Un libro de datos en python con una API para operaciones matemáticas.\n",
            "\n",
            "# importar numpy import numpy as np # crear un nuevo array de 5 elementos a = np.array([1, 2, 3, 4, 5]) # actualizar el valor de los elementos 2 y 3 a[2] = 9 a[3] = -11 # actualizar el valor de los elementos"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api completions.create -m davinci:ft-espol:clases-prueba-2023-09-02-19-04-03 -t 0.9 -M 100 -p \"Dame un ejemplo de un codigo para sumar dos arrays de numpy\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V66tSaQIVWOt",
        "outputId": "7bca0f6b-70ad-4438-a1e3-d8f403e94740"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dame un ejemplo de un codigo para sumar dos arrays de numpy?\n",
            "\n",
            "Este es mi codigo: import numpy as np a1 = np.arange(0,5,1) print(a1) b1 = np.arange(0,5,1) print(b1) print(a1 + b1)\n",
            "\n",
            "Crear array de nodos del eje de dirección x de una matriz de datos La tabla arTienes arTienes arTienes"
          ]
        }
      ]
    }
  ]
}